{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "829deb8e329e887a4f93cafb73fa8258",
     "grade": false,
     "grade_id": "cell-32a74bbca42bd5b8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Assignment 1\n",
    "\n",
    "We explored linear models the last lecture. We will strengthen this understanding by implementing linear and logistic regression models as part of the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section I - Linear Regression\n",
    "\n",
    "We will implement a linear regression model to fit a curve to some data. Since the data is nonlinear, we will implement polynomial regression and use ridge regression to implement the best possible fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6bda8b4c9dd4bc8887dc94ce790446b2",
     "grade": false,
     "grade_id": "cell-18e0f04906f35ade",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 1. Load Data and Visualize\n",
    "\n",
    "Let us load a dataset of points $(x,y)$. \n",
    "As a first step, let's import the required libraries followed by the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "082d82a660e1f1cb1b3d8cedfc4357a2",
     "grade": false,
     "grade_id": "cell-c023a1f94f8bc218",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape is  (300, 1)\n",
      "train_Y.shape is  (300, 1)\n",
      "test_X.shape is  (200, 1)\n",
      "test_Y.shape is  (200, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import ridge_reg_data\n",
    "\n",
    "# Libraries for evaluating the solution\n",
    "import pytest\n",
    "import numpy.testing as npt\n",
    "import random\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "train_X, train_Y, test_X, test_Y = ridge_reg_data() # Pre-defined function for loading the dataset\n",
    "train_Y = train_Y.reshape(-1,1) # reshaping from (m,) -> (m,1)\n",
    "test_Y = test_Y.reshape(-1,1)\n",
    "print('train_X.shape is ', train_X.shape)\n",
    "print('train_Y.shape is ', train_Y.shape)\n",
    "print('test_X.shape is ', test_X.shape)\n",
    "print('test_Y.shape is ', test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0edfb43772efad0bc41c79e885ce6feb",
     "grade": false,
     "grade_id": "cell-2720ad6352d5f32a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Visualize Data\n",
    "\n",
    "The dataset is split into train and test sets. The train set consists of 300 samples and the test set consists of 200 samples. We will use scatter plot to visualize the relationship between the '$x$' and '$y$'. Lets visualize the data using the scatter plot from [matplotlib](https://matplotlib.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b24d27ddb9db6d2ae3d7bdd73d63285",
     "grade": false,
     "grade_id": "cell-156aa27fccc1a7cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.scatter(train_X,train_Y,marker='o',s=4)\n",
    "plt.ylim(-2, 3)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c79901bcbe6c2ec7da75ec4c4f1a87e9",
     "grade": false,
     "grade_id": "cell-82c462d9db119ed5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Linear Regression - Polynomial Transformation\n",
    "\n",
    "Using the train data we hope to learn a relationship mapping $x$ to $y$. We can evaluate this mapping using the test data. Linear regression will try to fit a straight line (linear relation) mapping $x$ to $y$. However, we observe the $x$ and $y$ do not have a linear relationship. A straight line will not be a good fit. We need a non-linear mapping (curve) between $x$ and $y$. \n",
    "\n",
    "We discussed in the lecture that nonlinear regression can be achieved by transforming the scalar $x$ to a high dimension sample and performing linear regression with the transformed data. We can transform $x$ into a $d$ dimensional vector ($d \\geq 2$) in order to perform nonlinear regression. For example, $d = 5$ transforms $x$ into a $(d+1)$ dimension vector $[1,x,x^2,x^3,x^4,x^5]^\\top$, where $x^k$ is $x$ raised to $k$. In vectorized notation, the dataset $X$ is transformed to $\\Phi(X)$ of  dimension $m \\times (d+1)$, where $m$ is the number of samples. \n",
    "\n",
    "Every scalar $x$ is converted into a $(d+1)$ dimension vector, $[1,x_1,x_2,x_3,\\ldots,x_d]^\\top$. We can now perform linear regression in $(d+1)$ dimensions.\n",
    "\\begin{equation*}\n",
    "y = \\Phi(x)\\boldsymbol{\\theta} = \\theta_0 + x_1\\theta_1 + ... + x_{d-1}\\theta_{d-1} + x_d\\theta_d\\\\\n",
    "\\end{equation*}\n",
    "In the above equation, $y$ is the target variable, $\\boldsymbol{\\theta} = [\\theta_{0},.., \\theta_{d}]^\\top$ are the parameters/weights of the model, $\\Phi(x) = [1,x_{1},.., x_{d}]$ is the transformed data point in the row vector format, where $x_k$ is the $k^{th}$ component. \n",
    "    \n",
    "In the vectorized notation, the linear regression for $m$ samples is written as  $\\hat{Y} = \\Phi(X)\\boldsymbol{\\theta}$, where $\\Phi(X)$ has the data points as row vectors and is of dimensions $m \\times (d+1)$,\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{bmatrix} \\hat{y}^{(1)} \\\\ \n",
    "\\hat{y}^{(2)}\\\\\n",
    "\\vdots\\\\ \n",
    "\\hat{y}^{(m)}\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix} 1 & x^{(1)}_1 & x^{(1)}_2  & \\ldots & x^{(1)}_d\\\\ \n",
    "1 & x^{(2)}_1 & x^{(2)}_2  & \\ldots & x^{(2)}_d\\\\  \n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots\\\\ \n",
    "1 & x^{(m)}_1 & x^{(m)}_2  & \\ldots & x^{(m)}_d\\\\ \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} \\theta_0 \\\\ \n",
    "\\theta_1\\\\ \n",
    "\\vdots \\\\ \n",
    "\\theta_d\\\\ \n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "$X$ - is the Design matrix of dimension $m \\times (d+1) $, where $m$ is the number of samples and $d$ is the degree of the polynomial that we are trying to fit. The first column of 1's in the design matrix will account for the bias , resulting in $d+1$ dimensions <br>\n",
    "\n",
    "$Y$ - Vector of the prediction labels of dimension $m \\times 1 $.\n",
    "Lets implement a function to achieve this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4de9bcb62f04fc146678fe0ccba4a68a",
     "grade": false,
     "grade_id": "cell-poly_func",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def poly_transform(X,d):\n",
    "    '''\n",
    "    Function to transform scalar values into (d+1)-dimension vectors. \n",
    "    Each scalar value x is transformed a vector [1,x,x^2,x^3, ... x^d]. \n",
    "    \n",
    "    Inputs:\n",
    "        X: vector of m scalar inputs od shape (m, 1) where each row is a scalar input x\n",
    "        d: number of dimensions\n",
    "        \n",
    "    Outputs:\n",
    "        Phi: Transformed matrix of shape (m, (d+1)) \n",
    "    '''\n",
    "    Phi = np.ones((X.shape[0],1))\n",
    "    for i in range(1,d+1):\n",
    "        col = np.power(X,i)\n",
    "        Phi = np.hstack([Phi,col])\n",
    "    return Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 3 2]]\n",
      "[[1. 1. 2. 3.]\n",
      " [1. 4. 3. 2.]]\n"
     ]
    }
   ],
   "source": [
    "# print(train_X[:5,:])\n",
    "# print(train_Y[:5])\n",
    "# Phi = np.ones((train_X.shape[0],1))\n",
    "\n",
    "# for i in range(1,(train_X.shape[1]+4)):\n",
    "#     col = np.power(train_X, i)\n",
    "#     Phi = np.hstack([Phi,col])\n",
    "# print(Phi)\n",
    "\n",
    "# X = np.array([[[1],[2],[3]],[[4],[3],[2]]])\n",
    "X = np.array([[1,2,3],[4,3,2]])\n",
    "print(X)\n",
    "# print(X.shape)\n",
    "\n",
    "Phi = np.ones((X.shape[0],1))\n",
    "\n",
    "Phi = np.hstack([Phi,X])\n",
    "# print(col)\n",
    "print(Phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1778803059522c7eb8f2af002ed64124",
     "grade": false,
     "grade_id": "cell-973aaed232f7e02c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Linear Regression - Objective Function (5 Points)\n",
    "\n",
    "Let us define the objective function that will be optimized by the linear regression model.\n",
    "    \\begin{equation*}\n",
    "    L\\big(\\Phi(X),Y,\\theta\\big) = \\big(Y-\\Phi(X)\\boldsymbol{\\theta}\\big)^\\top \\big(Y-\\Phi(X)\\boldsymbol{\\theta}\\big)\n",
    "    \\end{equation*}\n",
    "\n",
    "Here, $\\Phi(X)$ is the design matrix of dimensions (m \\times (d+1)) and $Y$ is the $m$ dimension vector of labels. \n",
    "$\\theta$ is the $(d+1)$ dimension vector of weight parameters.\n",
    " \n",
    "Hint: You may want to use [numpy.dot](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "505f5ada0a45ae376bca76c2df323eeb",
     "grade": false,
     "grade_id": "test_case1_lin_reg_obj_soln",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def lin_reg_obj(Y,Phi,theta):\n",
    "    '''\n",
    "    Objective function to estimate loss for the linear regression model.\n",
    "    Inputs:\n",
    "        Phi: Design matrix of dimensions (m, (d+1))\n",
    "        Y: ground truth labels of dimensions (m, 1)\n",
    "        theta: Parameters of linear regression of dimensions ((d+1),1)\n",
    "        \n",
    "    outputs:\n",
    "        loss: scalar loss \n",
    "    '''\n",
    "    # your code here\n",
    "    loss = np.dot((Y-np.dot(Phi,theta)).T, (Y-np.dot(Phi,theta)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "939fdc75ed628b4994c0c16ac144b973",
     "grade": true,
     "grade_id": "test_case1_lin_reg_obj",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Contains hidden tests\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "m1 = 10;\n",
    "d1 = 5;\n",
    "X_t = np.random.randn(m1,1)\n",
    "Y_t = np.random.randn(m1,1)\n",
    "theta_t = np.random.randn((d1+1),1)\n",
    "PHI_t = poly_transform(X_t,d1)\n",
    "loss_est = lin_reg_obj(Y_t,PHI_t,theta_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ebe9df73c77ede248f3825b92bb20a9",
     "grade": false,
     "grade_id": "cell-8198b2d036843726",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Linear Regression - Closed Form Solution (10 Points)\n",
    "\n",
    "Let us define a closed form solution to the objective function. Feel free to revisit the lecture to review the topic.\n",
    "Closed form solution is given by,\n",
    "\n",
    "\\begin{equation*}\n",
    "\\theta = \\big(\\Phi(X)^\\top\\Phi(X)\\big)^{-1}\\Phi(X)^\\top Y\n",
    "\\end{equation*}\n",
    "\n",
    "Here $\\Phi(X)$ is the $(m \\times (d+1))$ dimension design matrix obtained using *poly_transform* function defined earlier and $Y$ are the ground truth labels of dimensions $(m \\times 1)$. \n",
    "\n",
    "Hint: You may want to use [numpy.linalg.inv](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.inv.html) and [numpy.dot](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e7e69fbec55968da428b17a20fd9329",
     "grade": false,
     "grade_id": "test_case2_closed_form_soln",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Closed form solution\n",
    "def lin_reg_fit(Phi_X,Y):\n",
    "    '''\n",
    "    A function to estimate the linear regression model parameters using the closed form solution.\n",
    "    Inputs:\n",
    "        Phi_X: Design matrix of dimensions (m, (d+1))\n",
    "        Y: ground truth labels of dimensions (m, 1)\n",
    "         \n",
    "    Outputs:\n",
    "        theta: Parameters of linear regression of dimensions ((d+1),1)\n",
    "    '''\n",
    "    # your code here\n",
    "    inverse =  np.linalg.inv(np.dot(Phi_X.T, Phi_X))\n",
    "    theta = np.dot(np.dot(inverse, Phi_X.T), Y)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ee76160fe3ac2ac70d3b352586ed9fe",
     "grade": true,
     "grade_id": "test_case2_closed_form",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Contains hidden tests\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "m1 = 10;\n",
    "d1 = 5;\n",
    "X_t = np.random.randn(m1,1)\n",
    "Y_t = np.random.randn(m1,1)\n",
    "PHI_t = poly_transform(X_t,d1)\n",
    "theta_est = lin_reg_fit(PHI_t,Y_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ff7e3a3e6108ad6242020bf5c64b5bb",
     "grade": false,
     "grade_id": "cell-562b211608e0da1c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Metrics for Evaluation (10 points)\n",
    "\n",
    "We will evaluate the goodness of our linear regression model using root mean square error. This compares the difference between the estimate Y-labels and the groundth truth Y-labels. The smaller the RMSE value, better is the fit. \n",
    "1. RMSE (Root Mean Squared Error)\n",
    "\\begin{equation*}\n",
    "\\sqrt{\\frac{1}{m}\\sum_{i=1}^{m}(y\\_pred^{(i)} - y^{(i)})^{2} }\n",
    "\\end{equation*}\n",
    "\n",
    "Hint: You may want to use:  \n",
    "[numpy.sqrt](https://numpy.org/doc/stable/reference/generated/numpy.sqrt.html),\n",
    "[numpy.sum](https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html) or [numpy.dot](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af2a7ec7a3bb2d57790227708089cad2",
     "grade": false,
     "grade_id": "test_case3_rmse_soln",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "def get_rmse(Y_pred,Y):\n",
    "    '''\n",
    "    function to evaluate the goodness of the linear regression model.\n",
    "    \n",
    "    Inputs:\n",
    "        Y_pred: estimated labels of dimensions (m, 1)\n",
    "        Y: ground truth labels of dimensions (m, 1)\n",
    "        \n",
    "    Outputs:\n",
    "        rmse: root means square error\n",
    "    '''\n",
    "    # your code here\n",
    "    rmse = np.sqrt(np.mean(np.square(Y_pred-Y)))\n",
    "#     rmse = np.sqrt(metrics.mean_squared_error(Y_pred,Y))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffadb55d1706eeb293e17835bc8e830d",
     "grade": true,
     "grade_id": "test_case3_rmse",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Contains hidden tests\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "m1 = 50\n",
    "Y_Pred_t = np.random.randn(m1,1)\n",
    "Y_t = np.random.randn(m1,1)\n",
    "rmse_est = get_rmse(Y_Pred_t,Y_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dfbb7b35c2b02d0560e23342f679007f",
     "grade": false,
     "grade_id": "cell-a510a78a331859fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's visualize the nonlinear regression fit and the RMSE evaluation error on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11a08c005070725d28b9cc0b8c17ea20",
     "grade": false,
     "grade_id": "cell-bde15c011e06f29f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE =  0.513634052031467\n",
      "Test RMSE =  0.5037663916729039\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = 20\n",
    "Phi_X_tr = poly_transform(train_X,d)\n",
    "theta = lin_reg_fit(Phi_X_tr,train_Y)\n",
    "#Estimate the prediction on the train data\n",
    "Y_Pred_tr = np.dot(Phi_X_tr,theta)\n",
    "rmse = get_rmse(Y_Pred_tr,train_Y)\n",
    "print('Train RMSE = ', rmse)\n",
    "\n",
    "#Perform the same transform on the test data\n",
    "Phi_X_ts = poly_transform(test_X,d)\n",
    "#Estimate the prediction on the test data\n",
    "Y_Pred_ts = np.dot(Phi_X_ts,theta)\n",
    "#Evaluate the goodness of the fit\n",
    "rmse = get_rmse(Y_Pred_ts,test_Y)\n",
    "print('Test RMSE = ', rmse)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.scatter(test_X,test_Y,marker='o',s=4)\n",
    "# Sampling more points to plot a smooth curve\n",
    "px = np.linspace(-2,2,100).reshape(-1,1)\n",
    "PX = poly_transform(px,d)\n",
    "py = np.dot(PX,theta)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.ylim(-2, 3)\n",
    "plt.plot(px,py,color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "beb1c846e0889a6cc1be2874640571ec",
     "grade": false,
     "grade_id": "cell-f84306ac0b0e9126",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. Ridge Regression \n",
    "\n",
    "The degree of the polynomial regression is $d=10$. Even though the curve appears to be smooth, it may be fitting to the noise. We will use Ridge Regression to get a smoother fit and avoid-overfitting. Recall the ridge regression objective form:\n",
    "\n",
    "\\begin{equation*}\n",
    "    L\\big(\\Phi(X),Y,\\theta, \\lambda\\big) = \\big(Y-\\Phi(X)\\boldsymbol{\\theta}\\big)^\\top \\big(Y-\\Phi(X)\\boldsymbol{\\theta}\\big) + \\lambda^2\\boldsymbol{\\theta}^\\top\\boldsymbol{\\theta}\n",
    "\\end{equation*}\n",
    "where, $\\lambda\\geq 0$ is the regularization parameter. Larger the value of $\\lambda$, the more smooth the curve. The closed form solution to the objective is give by: \n",
    "\n",
    "\\begin{equation*}\n",
    "\\theta = \\big(\\Phi(X)^\\top\\Phi(X) + \\lambda^2I_d \\big)^{-1}\\Phi(X)^\\top Y\n",
    "\\end{equation*}\n",
    "\n",
    "Here, $I_d$ is the identity matrix of dimensions $((d+1) \\times (d+1))$, $\\Phi(X)$ is the $(m \\times (d+1))$ dimension design matrix obtained using *poly_transform* function defined earlier and $Y$ are the ground truth labels of dimensions $(m \\times 1)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression Closed Form Solution (5 points)\n",
    "\n",
    "Similar to Linear regression, lets implement the closed form solution to ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "405c311e3db8fe80ab42bc9d24c38a94",
     "grade": false,
     "grade_id": "test_case4_ridge_soln",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ridge_reg_fit(Phi_X,Y,lamb_d):\n",
    "    '''\n",
    "    A function to estimate the ridge regression model parameters using the closed form solution.\n",
    "    Inputs:\n",
    "        Phi_X: Design matrix of dimensions (m, (d+1))\n",
    "        Y: ground truth labels of dimensions (m, 1)\n",
    "        lamb_d: regularization parameter\n",
    "         \n",
    "    Outputs:\n",
    "        theta: Parameters of linear regression of dimensions ((d+1),1)\n",
    "    '''\n",
    "    #Step 1: get the dimension dplus1 using Phi_X to create the identity matrix $I_d$\n",
    "    #Step 2: Estimate the closed form solution similar to *linear_reg_fit* but now includethe lamb_d**2*I_d term\n",
    "    # your code here\n",
    "    lamb_dEye = np.multiply(lamb_d**2, np.eye(Phi_X.shape[1],Phi_X.shape[1]))\n",
    "    inverse = np.linalg.inv(np.add((np.dot(Phi_X.T, Phi_X)),lamb_dEye))\n",
    "    theta = np.dot(np.dot(inverse,Phi_X.T),Y)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fe09208485f0d05e2bbcf320255baab",
     "grade": true,
     "grade_id": "test_case4_ridge",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Contains hidden tests\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "m1 = 10;\n",
    "d1 = 5;\n",
    "lamb_d_t = 0.1\n",
    "X_t = np.random.randn(m1,1)\n",
    "Y_t = np.random.randn(m1,1)\n",
    "PHI_t = poly_transform(X_t,d1)\n",
    "theta_est = ridge_reg_fit(PHI_t,Y_t,lamb_d_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6800d337a86d1ebce62552fe1be49846",
     "grade": false,
     "grade_id": "cell-9fd42614f0a882a7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Cross Validation to Estimate ($\\lambda$)\n",
    "\n",
    "In order to avoid overfitting when using a high degree polynomial, we have used **ridge regression**. We now need to estimate the optimal value of $\\lambda$ using **cross-validation**.\n",
    "\n",
    "We will obtain a generic value of $\\lambda$ using the entire training dataset to validate. We will employ the method of **$k$-fold cross validation**, where we split the training data into $k$ non-overlapping random subsets. In every cycle, for a given value of $\\lambda$, $(k-1)$ subsets are used for training the ridge regression model and the remaining subset is used for evaluating the goodness of the fit. We estimate the average goodness of the fit across all the subsets and select the $lambda$ that results in the best fit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e343c0eda71cc62a6808886bb2569f1",
     "grade": false,
     "grade_id": "cell-90d40e75daa8feef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "![K-fold cross validation](images/kfold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e559b6b17bd8aa879dd1bddad1c7c8d",
     "grade": false,
     "grade_id": "cell-96d803a3833c72df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "It is easier to shuffle the index and slice the training into required number of segments, than processing the complete dataset. The below function **k_val_ind$()$** returns a 2D list of indices by spliting the datapoints into  '$k\\_fold$'  sets\n",
    "\n",
    "Refer the following documentation for splitting and shuffling:\n",
    "\n",
    "- https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.shuffle.html\n",
    "- https://docs.scipy.org/doc/numpy/reference/generated/numpy.split.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1635c75c1527de81a46d4546e224c714",
     "grade": false,
     "grade_id": "cell-9f25cba02cb4420b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def k_val_ind(index,k_fold,seed=1):\n",
    "    '''\n",
    "    Function to split the data into k folds for cross validation. Returns the indices of the data points \n",
    "    belonging to every split.\n",
    "    \n",
    "    Inputs:\n",
    "        index: all the indices of the training\n",
    "        k_fold: number of folds to split the data into\n",
    "    \n",
    "    Outputs:\n",
    "        k_set: list of arrays with indices\n",
    "    ''' \n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(index) # Shuffle the indices\n",
    "    k_set = np.split(index,k_fold) # Split the indices into 'k_fold' \n",
    "    return k_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4af98cf3581180550c097b3bc5960642",
     "grade": false,
     "grade_id": "cell-b114c1ebca476cef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### K- Fold Cross Validation (10 Points)\n",
    "\n",
    "Let's now implement $k$-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f57aa21ac91806c1ebdfe878f83fb9d",
     "grade": false,
     "grade_id": "test_case5_k_fold_soln",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def k_fold_cv(k_fold,train_X,train_Y,lamb_d,d):\n",
    "    '''\n",
    "    Function to implement k-fold cross validation.\n",
    "    Inputs:\n",
    "        k_fold: number of validation subsests\n",
    "        train_X: training data of dimensions (m, 1) \n",
    "        train_Y: ground truth training labels\n",
    "        lamb_d: ridge regularization lambda parameter\n",
    "        d: polynomial degree\n",
    "        \n",
    "    Outputs:\n",
    "        rmse_list: list of root mean square errors (RMSE) for k_folds \n",
    "    '''\n",
    "    index = np.arange(train_X.shape[0]) # indices of the training data\n",
    "    k_set = k_val_ind(index,k_fold) # pre-defined function to shuffle and split indices \n",
    "\n",
    "    Phi_X = poly_transform(train_X, d) #transform all the data to (m,(d+1)) dimensions\n",
    "    rmse_list = [] \n",
    "    for i in range(k_fold):\n",
    "        ind = np.zeros(train_X.shape[0], dtype=bool) # binary mask\n",
    "        ind[k_set[i]] = True # validation portion is indicated\n",
    "\n",
    "        #Note: Eg. train_X[ind] -> validation set, train_X[~ind] -> training set \n",
    "        # Write your answer inside the 'for' loop\n",
    "        # Note: Phi_X[~ind,:] is training subset and Phi_X[ind,:] is validation subset. Similary for the train and validation labels.\n",
    "        # Step 1: Estimate the theta parameter using ridge_reg_fit with the training subset, training labels and lamb_d\n",
    "        # Step 2: Estimate the prediction Y_pred over the validation as a dot product over Phi_X[ind,:] and theta\n",
    "        # Step 3: use 'get_rmse' function to determine rmse using Y_pred and train_Y[ind]\n",
    "        \n",
    "        # your code here\n",
    "        Phi_X_tr = poly_transform(train_X[~ind,:],d)\n",
    "        theta = ridge_reg_fit(Phi_X_tr,train_Y[~ind,:],lamb_d)\n",
    "        #Estimate the prediction on the train data\n",
    "        Y_Pred_tr = np.dot(Phi_X_tr,theta)\n",
    "#         rmse = get_rmse(Y_Pred_tr,train_Y[~ind])\n",
    "#         print('Train RMSE = ', rmse)\n",
    "\n",
    "        #Perform the same transform on the test data\n",
    "        Phi_X_vl = poly_transform(train_X[ind,:],d)\n",
    "        #Estimate the prediction on the test data\n",
    "        Y_Pred_vl = np.dot(Phi_X_vl,theta)\n",
    "        #Evaluate the goodness of the fit\n",
    "        rmse = get_rmse(Y_Pred_vl,train_Y[ind])\n",
    "#         print('Test RMSE = ', rmse)\n",
    "\n",
    "        \n",
    "        rmse_list.append(rmse)\n",
    "    return rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4af9a2c4800c30dd3ff76b444ad52383",
     "grade": true,
     "grade_id": "test_case5_k_fold",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Contains hidden tests\n",
    "\n",
    "np.random.seed(1)\n",
    "m1 = 20;\n",
    "d1 = 5;\n",
    "k_fold_t = 5 # number of portions to split the training data\n",
    "lamb_d_t = 0.1\n",
    "X_t = np.random.randn(m1,1)\n",
    "Y_t = np.random.randn(m1,1)\n",
    "\n",
    "rmse_list_est = k_fold_cv(k_fold_t,X_t,Y_t,lamb_d_t,d1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "042925615ce42cfacde44f6e8c123664",
     "grade": false,
     "grade_id": "cell-504dec0a4f62dce1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let us select the value of $\\lambda$ that provides the lowest error based on RMSE returned by the 'k_fold_cv' function.\n",
    "\n",
    "In this example, we will choose the best value of $\\lambda$ among 6 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5d42a96649f743ac378ec5667c20ed9",
     "grade": false,
     "grade_id": "evaluate_best_lambda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda:0\n",
      "RMSE:  [0.900954295623315, 0.5994803208934071, 0.4889900288640249, 0.573527019641338, 0.5778677359302081]\n",
      "*************\n",
      "lambda:0.001\n",
      "RMSE:  [0.9256125413643892, 0.6019049191502326, 0.4886839013160882, 0.570851998218019, 0.578453580585335]\n",
      "*************\n",
      "lambda:0.01\n",
      "RMSE:  [1.0459150607219652, 0.6251818344585315, 0.49331521800220113, 0.557059022674058, 0.5899606198111953]\n",
      "*************\n",
      "lambda:0.1\n",
      "RMSE:  [0.8261469892856536, 0.6465246728225232, 0.4903313064988208, 0.5660950135649823, 0.594567056973814]\n",
      "*************\n",
      "lambda:1\n",
      "RMSE:  [0.6799665281582076, 0.6886693538180663, 0.5647357571721459, 0.6393075143501448, 0.6470329226897773]\n",
      "*************\n",
      "lambda:10\n",
      "RMSE:  [0.733526104199645, 0.6993069184744143, 0.7556132498851601, 0.7992608700240204, 0.8199075014797217]\n",
      "*************\n",
      "Best value for the regularization parameter(lamb_d): 0.1\n"
     ]
    }
   ],
   "source": [
    "k_fold = 5 \n",
    "l_range = [0,1e-3,1e-2,1e-1,1,10] # The set of lamb_d parameters used for validation.\n",
    "th = float('inf')\n",
    "for lamb_d in l_range:     \n",
    "    print('lambda:'+str(lamb_d))\n",
    "    rmse = k_fold_cv(k_fold,train_X,train_Y,lamb_d,d)\n",
    "    print(\"RMSE: \",rmse)\n",
    "    print(\"*************\")\n",
    "    mean_rmse = np.mean(rmse)\n",
    "    if mean_rmse<th:\n",
    "        th = mean_rmse\n",
    "        l_best = lamb_d\n",
    "\n",
    "print(\"Best value for the regularization parameter(lamb_d):\",l_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6247330078291589\n"
     ]
    }
   ],
   "source": [
    "a = float('inf')\n",
    "a = th\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b5647a7ae669d68bd5d0e45fc2c35f9",
     "grade": false,
     "grade_id": "cell-ad8d5b46266cc238",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Evaluation on the Test Set (10 Points)\n",
    "\n",
    "As discussed in previous section, we will present the final evaluation of the model based on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f23ae9a7c340f0a29dca6b8409b9eadf",
     "grade": false,
     "grade_id": "test_case6_test_eval_soln",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test set is 0.4985009962619602\n"
     ]
    }
   ],
   "source": [
    "lamb_d = l_best\n",
    "\n",
    "# Step 1: Create Phi_X using 'poly_transform(.)' on the train_X and d=20\n",
    "# Step 2: Estimate theta using ridge_reg_fit(.) with Phi_X, train_Y and the best lambda\n",
    "# Step 3: Create Phi_X_test using 'poly_transform(.)' on the test_X and d=20\n",
    "# Step 4: Estimate the Y_Pred for the test data using Phi_X_test and theta\n",
    "# Step 5: Estimate rmse using get_rmse(.) on the Y_Pred and test_Y \n",
    "\n",
    "# your code here\n",
    "d = 20\n",
    "Phi_X = poly_transform(train_X,d)\n",
    "theta = ridge_reg_fit(Phi_X,train_Y,lamb_d)\n",
    "Phi_X_ts = poly_transform(test_X,d)\n",
    "Y_Pred_ts = np.dot(Phi_X_ts,theta)\n",
    "rmse = get_rmse(Y_Pred_ts,test_Y)\n",
    "\n",
    "print(\"RMSE on test set is \"+str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a552b67d41fea73788eae5c21d29ef90",
     "grade": true,
     "grade_id": "test_case6_test_eval",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Contains hidden tests checking for rmse < 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee53e6bd8130eb2de3b26b416a8e189b",
     "grade": false,
     "grade_id": "cell-d3a8085e8fb78c6a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's visualize the model's prediction on the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71dd4e0490d251a6f21f51ec2f3b8244",
     "grade": false,
     "grade_id": "cell-3b03fae185cb3ca0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE =  0.4985009962619602\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Test RMSE = ', rmse)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.scatter(test_X,test_Y,marker='o',s=4)\n",
    "# Sampling more points to plot a smooth curve\n",
    "px = np.linspace(-2,2,100).reshape(-1,1)\n",
    "PX = poly_transform(px,d)\n",
    "py = np.dot(PX,theta)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.ylim(-2, 3)\n",
    "plt.plot(px,py,color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52683baeb15aa2d5d4cd91096899fc16",
     "grade": false,
     "grade_id": "cell-a7c8603b7da65b99",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "You have completed linear ridge regression and estimated the best value for the regularization parameter $\\lambda$ using k-fold cross validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d2244633a1b32321d679ea371761aba",
     "grade": false,
     "grade_id": "cell-e8eeecd017a348a4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Section II - Logistic Regression\n",
    "\n",
    "Machine learning is used in medicine for assisting doctors with crucial decision-making based on dignostic data. \n",
    "In this assignment we will be designing a logistic regression model (single layer neural network) to predict if a subject is diabetic or not. The model will classify the subjects into two groups diabetic (Class 1) or non-diabetic (Class 0) - a binary classification model.\n",
    "\n",
    "We will be using the 'Pima Indians Diabetes dataset' to train our model which contains different clinical parameters (features) for multiple subjects along with the label (diabetic or not-diabetic). Each  subject is represented by 8 features (Pregnancies, Glucose, Blood-Pressure, SkinThickness, Insulin, BMI, Diabetes-Pedigree-Function, Age) and the 'Outcome' which is the class label. The dataset contains the results from 768 subjects.\n",
    "\n",
    "We will be spliting the dataset into train and test data. We will train our model on the train data and predict the categories on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d4bf90e6f741c532368a785b2214def",
     "grade": false,
     "grade_id": "logistic_libraries_import",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#importing a few libraries\n",
    "import numpy as np\n",
    "from datasets import pima_data\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.testing as npt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d73748b77b16f0b8e54ef003a62d8700",
     "grade": false,
     "grade_id": "cell-b11dd0b0cb9855e4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 1. Load Data, Visualize and Normalize\n",
    "\n",
    "Let us load the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ec2d9c682767e9341c463b61e4e21fa",
     "grade": false,
     "grade_id": "call_load_diabetes_dataset",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape =  (500, 8)\n",
      "train_Y.shape =  (500,)\n",
      "test_X.shape =  (268, 8)\n",
      "test_Y.shape =  (268,)\n",
      "\n",
      "Few Train data examples\n",
      "[[6.000e+00 1.480e+02 7.200e+01 3.500e+01 0.000e+00 3.360e+01 6.270e-01\n",
      "  5.000e+01]\n",
      " [1.000e+00 8.500e+01 6.600e+01 2.900e+01 0.000e+00 2.660e+01 3.510e-01\n",
      "  3.100e+01]\n",
      " [8.000e+00 1.830e+02 6.400e+01 0.000e+00 0.000e+00 2.330e+01 6.720e-01\n",
      "  3.200e+01]\n",
      " [1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
      "  2.100e+01]\n",
      " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
      "  3.300e+01]]\n",
      "\n",
      "Few Train data labels\n",
      "[1. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "train_X,train_Y,test_X,test_Y  = pima_data()\n",
    "\n",
    "print('train_X.shape = ', train_X.shape)\n",
    "print('train_Y.shape = ', train_Y.shape)\n",
    "print('test_X.shape = ', test_X.shape)\n",
    "print('test_Y.shape = ', test_Y.shape)\n",
    "\n",
    "# Lets examine the data\n",
    "print('\\nFew Train data examples')\n",
    "print(train_X[:5, :])\n",
    "print('\\nFew Train data labels')\n",
    "print(train_Y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23d5f17124b14be46d486ffa19ea4a6d",
     "grade": false,
     "grade_id": "reshape_normalize_data",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape =  (8, 500)\n",
      "train_Y.shape =  (1, 500)\n",
      "test_X.shape =  (8, 268)\n",
      "test_Y.shape =  (1, 268)\n",
      "\n",
      "Few Train data examples\n",
      "[[0.35294118 0.05882353 0.47058824 0.05882353 0.        ]\n",
      " [0.74371859 0.42713568 0.91959799 0.44723618 0.68844221]\n",
      " [0.59016393 0.54098361 0.52459016 0.54098361 0.32786885]\n",
      " [0.35353535 0.29292929 0.         0.23232323 0.35353535]\n",
      " [0.         0.         0.         0.11111111 0.19858156]\n",
      " [0.50074516 0.39642325 0.34724292 0.41877794 0.64232489]\n",
      " [0.25909091 0.14504132 0.27768595 0.06900826 0.94545455]\n",
      " [0.61728395 0.38271605 0.39506173 0.25925926 0.40740741]]\n",
      "\n",
      "Few Train data labels\n",
      "[1. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# We notice the data is not normalized. Lets do a simple normalization scaling to data between 0 and 1\n",
    "# Normalized data is easier to train using large learning rates\n",
    "train_X = np.nan_to_num(train_X/train_X.max(axis=0))\n",
    "test_X = np.nan_to_num(test_X/test_X.max(axis=0))\n",
    "\n",
    "#Lets reshape the data so it matches our notation from the lecture. \n",
    "#train_X should be (d, m) and train_Y should (1,m) similarly for test_X and test_Y\n",
    "train_X = train_X.T\n",
    "train_Y= train_Y.reshape(1,-1)\n",
    "\n",
    "test_X = test_X.T\n",
    "test_Y= test_Y.reshape(1,-1)\n",
    "print('train_X.shape = ', train_X.shape)\n",
    "print('train_Y.shape = ', train_Y.shape)\n",
    "print('test_X.shape = ', test_X.shape)\n",
    "print('test_Y.shape = ', test_Y.shape)\n",
    "\n",
    "# Lets examine the data and verify it is normalized\n",
    "print('\\nFew Train data examples')\n",
    "print(train_X[:, :5])\n",
    "print('\\nFew Train data labels')\n",
    "print(train_Y[0,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be3b48d4384b4a15d8da1bacad09a361",
     "grade": false,
     "grade_id": "visualize_diabetes_data",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#There are 8 features for each of the data points. Lets plot the data using a couple of features\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(train_X[6,:],train_X[7,:], c=train_Y[0])\n",
    "plt.xlabel('Diabetes-Pedigree-Function')\n",
    "plt.ylabel('Age')\n",
    "plt.show();\n",
    "# We have plotted train_X[6,:],train_X[7,:]. \n",
    "# Feel free to insert your own cells to plot and visualize different variable pairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9aceaf79c55e015b8be5cb472ac5f978",
     "grade": false,
     "grade_id": "cell-14e2d8a3057c00ec",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 2. Quick Review of the Steps Involved in Logistic Regression Using Gradient Descent.\n",
    "\n",
    "1. Training data $X$ is of dimensions $(d \\times m)$ where $d$ is number of features and $m$ is number of samples. Training labels $Y$ is of dimensions $(1 \\times m)$. \n",
    "\n",
    "2. Initilaize logistic regression model parameters $w$ and $b$ where $w$ is of dimensions $(d, 1)$ and $b$ is a scalar. $w$ is initialized to small random values and $b$ is set to zero\n",
    "\n",
    "3. Calculate $Z$ using $X$ and intial parameter values $(w , b)$ \n",
    "<center> \n",
    "    \\begin{equation*}\n",
    "     Z= w^\\top X + b\n",
    "    \\end{equation*}\n",
    "</center>\n",
    "\n",
    "4. Apply the sigmoid activation to estimate $A$ on $Z$,\n",
    "<center> \n",
    "    \\begin{equation*}\n",
    "     A=\\frac{1}{1+\\text{exp}(-Z)}\n",
    "    \\end{equation*}\n",
    "</center>\n",
    "\n",
    "5. Calculate the loss $L()$ between predicted probabilities $A$ and groundtruth labels $Y$,\n",
    "<center> \n",
    "    \\begin{equation*}\n",
    "     loss = logistic\\_loss(A,Y)\n",
    "    \\end{equation*}\n",
    "</center>\n",
    "\n",
    "4. Calculate gradient dZ (or $\\frac{dL}{dZ}$),\n",
    "<center> \n",
    "    \\begin{equation*}\n",
    "     dZ = (A - Y)\n",
    "    \\end{equation*}\n",
    "</center>\n",
    "\n",
    "5. Calculate gradients $\\frac{dL}{dw}$ represented by $dw$, $\\frac{dL}{db}$ represented by $db$\n",
    "<center> \n",
    "    \\begin{equation*}\n",
    "     dw,db = grad\\_fn(X ,dZ)\n",
    "    \\end{equation*}\n",
    "</center>\n",
    "6. Adjust the model parameters using the gradients. Here $\\alpha$ is the learning rate.\n",
    "<center> \n",
    "    \\begin{equation*}\n",
    "     w := w - \\alpha.dw\\\\\n",
    "     b := b - \\alpha.db\n",
    "    \\end{equation*}\n",
    "</center>\n",
    "7. Loop until the loss converges or for a fixed number of epochs. \n",
    "We will first define the functions **logistic_loss()** and **grad_fn()** along with other functions below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "![Lecture Notes](images/lecture_notes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aae97c14c5cbec91d0eb907b260f018c",
     "grade": false,
     "grade_id": "cell-0ca673d4d31d5a81",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Intialize Parameters (5 Points)\n",
    "\n",
    "we will initialize the model parameters. The weights will be initialized with small random values and bias as 0. While the bias will be a scalar, the dimension of weight vector will be $(d \\times 1)$, where $d$ is the number of features.\n",
    "\n",
    "\n",
    "Hint:[np.random.randn](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.random.randn.html) can be used here to create a vector of random integers of desired shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6764ca2431158d254b4956233ff852a7",
     "grade": false,
     "grade_id": "test_case7_initialize_soln",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def initialize(d, seed=1):\n",
    "    '''\n",
    "    Function to initialize the parameters for the logisitic regression model\n",
    "    \n",
    "    Inputs:\n",
    "        d: number of features for every data point\n",
    "        seed: random generator seed for reproducing the results\n",
    "        \n",
    "    Outputs:\n",
    "        w: weight vector of dimensions (d, 1)\n",
    "        b: scalar bias value\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # NOTE: initialize w to be a (d,1) column vector instead of (d,) vector \n",
    "    # Hint: initialize w to a random vector with small values. For example, 0.01*np.random.randn(.) can be used.\n",
    "    #       and initialize b to scalar 0\n",
    "    # your code here\n",
    "    w = np.random.randn(d,1) * 0.01\n",
    "#     b = np.zeros((d,1))\n",
    "    b = 0\n",
    "    \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e64b722c61fdf5e1c4f1259f346ba1b9",
     "grade": true,
     "grade_id": "test_case7_initialize",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Contains hidden tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.01624345],\n",
      "       [-0.00611756],\n",
      "       [-0.00528172]]), 0)\n"
     ]
    }
   ],
   "source": [
    "print(initialize(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd1dffc7dfa131361bfbf632d1258b95",
     "grade": false,
     "grade_id": "cell-6b8460e10ba5fa76",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Sigmoid Function (5 Points)\n",
    "\n",
    "Let's now implement Sigmoid activation function.\n",
    "\n",
    "<center> \n",
    "    \\begin{equation*}\n",
    "    \\sigma \\left(z\\right) = \\frac{1}{1+\\text{exp}(-z)}\n",
    "    \\end{equation*}\n",
    "</center>\n",
    "\n",
    "where z is in the input variable.\n",
    "Hint: [numpy.exp](https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html) can be used for defining the exponential function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70fbfdf02bc2c7125d7fce3cbfbcf354",
     "grade": false,
     "grade_id": "test_case8_sigmoid_soln",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # your code here\n",
    "    A = 1/(1 + np.exp(-z))\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5d86d2726bdb9ebeb2ed8a17bcb5494",
     "grade": true,
     "grade_id": "test_case8_sigmoid",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Contains hidden tests \n",
    "\n",
    "np.random.seed(1)\n",
    "d = 2\n",
    "m1 = 5\n",
    "X_t = np.random.randn(d,m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9975273768433653\n"
     ]
    }
   ],
   "source": [
    "print(sigmoid(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e33ee4649f724eac22fa20bbba370a6d",
     "grade": false,
     "grade_id": "cell-544d573972009ef1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Logistic Loss Function (5 Points)\n",
    "\n",
    "We will define the objective function that will be used later for determining the loss between the model prediction and groundtruth labels. We will use vectors $A$ (activation output of the logistic neuron) and $Y$ (groundtruth labels) for defining the loss. \n",
    "\n",
    "<center> \n",
    "    \\begin{equation*}\n",
    "    L(A,Y) = -\\frac{1}{m}\\sum_{i =1}^{m}y^{(i)}\\text{log} a^{(i)} + (1-y^{(i)}) \\text{log}( 1 - a^{(i)})\n",
    "    \\end{equation*}\n",
    "</center>\n",
    "\n",
    "where $m$ is the number of input datapoints and is used for averaging the total loss.\n",
    "Hint: [numpy.sum](https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html) and [numpy.log](https://docs.scipy.org/doc/numpy/reference/generated/numpy.log.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7d752866e502bfa5348492d1956d975",
     "grade": false,
     "grade_id": "test_case9_loss_soln",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def logistic_loss(A,Y):\n",
    "    '''\n",
    "    Function to calculate the logistic loss given the predictions and the targets.\n",
    "    \n",
    "    Inputs:\n",
    "        A: Estimated prediction values, A is of dimension (1, m)\n",
    "        Y: groundtruth labels, Y is of dimension (1, m)\n",
    "        \n",
    "    Outputs:\n",
    "        loss: logistic loss\n",
    "    '''\n",
    "    m = A.shape[1]\n",
    "    # your code here\n",
    "    loss = np.sum(np.multiply(-Y, np.log(A)) + np.multiply(-(1-Y), np.log(1-A)))/m\n",
    "#     loss =-(1/m) * np.sum(np.multiply(Y, np.log(A)) + np.multiply((1-Y), np.log(1-A)))\n",
    "\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81808f39a2854de217dc890e77bf3067",
     "grade": true,
     "grade_id": "test_case9_loss",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Contains hidden tests \n",
    "\n",
    "np.random.seed(1)\n",
    "d = 2\n",
    "m1 = 10\n",
    "X_t = np.random.randn(d,m1)\n",
    "Y_t = np.random.rand(1,m1)\n",
    "Y_t[Y_t>0.5] = 1\n",
    "Y_t[Y_t<=0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6950087090914167\n"
     ]
    }
   ],
   "source": [
    "w,b = initialize(2, 1)\n",
    "X = np.random.randn(2,10)\n",
    "Y = np.random.rand(1,10)\n",
    "A = sigmoid(np.dot(w.T,X) + b)\n",
    "loss = logistic_loss(A,Y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "882c173c85c6a40a03802eeebb201d2b",
     "grade": false,
     "grade_id": "cell-773df530bc7d1531",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Gradient Function (5 Points)\n",
    "\n",
    "Let us define the gradient function for calculating the gradients ($\\frac{dL}{dw},\\frac{dL}{db}$). We will use it during gradient descent.\n",
    "\n",
    "The gradients can be calculated as,\n",
    "<center> \n",
    "    \\begin{equation*}\n",
    "    dw = \\frac{1}{m}X( A- Y)^{T}\\\\\n",
    "    db = \\frac{1}{m}\\sum_{i =1}^{m} (a^{(i)} - y^{(i)})\n",
    "    \\end{equation*}\n",
    "</center>\n",
    "\n",
    "Instead of $(A-Y)$, we will use dZ (or $\\frac{dL}{dZ}$) since,\n",
    "<center> \n",
    "    \\begin{equation*}\n",
    "    dZ = \\left( A- Y\\right)\n",
    "    \\end{equation*}\n",
    "</center>\n",
    "Make sure the gradients are of correct dimensions. Refer to lecture for more information.\n",
    "\n",
    "Hint: [numpy.dot](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html) and\n",
    "[numpy.sum](https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html). Check use of 'keepdims' parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e42402d4cea9e648e36d6fd2ac1f1d98",
     "grade": false,
     "grade_id": "test_case10_gradient_soln",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def grad_fn(X,dZ):\n",
    "    '''\n",
    "    Function to calculate the gradients of weights (dw) and biases (db) w.r.t the objective function L.\n",
    "    \n",
    "    Inputs:\n",
    "        X: training data of dimensions (d, m)\n",
    "        dZ: gradient dL/dZ where L is the logistic loss and Z = w^T*X+b is the input to the sigmoid activation function\n",
    "            dZ is of dimensions (1, m)\n",
    "        \n",
    "    outputs:\n",
    "        dw: gradient dL/dw - gradient of the weight w.r.t. the logistic loss. It is of dimensions (d,1)\n",
    "        db: gradient dL/db - gradient of the bias w.r.t. the logistic loss. It is a scalar\n",
    "    '''\n",
    "    m = X.shape[1]\n",
    "    # your code here\n",
    "#     dw = (1/m) * X.dot(dZ.T)\n",
    "#     db = (1/m) * np.sum(dZ, axis = 1, keepdims = True)\n",
    "    dw = (1/m) * np.dot(X, dZ.T)\n",
    "    db = (1/m) * np.sum(dZ, axis = 1, keepdims = True)\n",
    "    \n",
    "    return dw,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c32913d79f9f7d9b0346cce83affc8e9",
     "grade": true,
     "grade_id": "test_case10_gradient",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Contains hidden tests \n",
    "\n",
    "np.random.seed(1)\n",
    "d = 2\n",
    "m1 = 10\n",
    "X_t = np.random.randn(d,m1)\n",
    "Y_t = np.random.rand(1,m1)\n",
    "Y_t[Y_t>0.5] = 1\n",
    "Y_t[Y_t<=0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.62434536 -0.61175641 -0.52817175 -1.07296862  0.86540763 -2.3015387\n",
      "   1.74481176 -0.7612069   0.3190391  -0.24937038]\n",
      " [ 1.46210794 -2.06014071 -0.3224172  -0.38405435  1.13376944 -1.09989127\n",
      "  -0.17242821 -0.87785842  0.04221375  0.58281521]]\n"
     ]
    }
   ],
   "source": [
    "print(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 1. 1. 0. 1. 1. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model (10 Points)\n",
    "\n",
    "We will now implement the steps for gradient descent discussed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83ab809038b51b750a5c903b619fc3c6",
     "grade": false,
     "grade_id": "test_case11_train_soln",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def model_fit(w,b,X,Y,alpha,n_epochs,log=False):\n",
    "    '''\n",
    "    Function to fit a logistic model with the parameters w,b to the training data with labels X and Y.\n",
    "    \n",
    "    Inputs:\n",
    "        w: weight vector of dimensions (d, 1)\n",
    "        b: scalar bias value\n",
    "        X: training data of dimensions (d, m)\n",
    "        Y: training data labels of dimensions (1, m)\n",
    "        alpha: learning rate\n",
    "        n_epochs: number of epochs to train the model\n",
    "        \n",
    "    Outputs:\n",
    "        params: a dictionary to hold parameters w and b\n",
    "        losses: a list train loss at every epoch\n",
    "    '''\n",
    "    losses=[]\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # Implement the steps in the logistic regression using the functions defined earlier.\n",
    "        # For each iteration of the for loop\n",
    "            # Step 1: Calculate output Z = w.T*X + b\n",
    "            # Step 2: Apply sigmoid activation: A = sigmoid(Z)\n",
    "            # Step 3: Calculate loss = logistic_loss(.) between predicted values A and groundtruth labels Y\n",
    "            # Step 4: Estimate gradient dZ = A-Y\n",
    "            # Step 5: Estimate gradients dw and db using grad_fn(.).\n",
    "            # Step 6: Update parameters w and b using gradients dw, db and learning rate\n",
    "            #         w = w - alpha * dw\n",
    "            #         b = b - alpha * db\n",
    "\n",
    "        # your code here\n",
    "        Z = np.dot(w.T, X) + b\n",
    "        A = sigmoid(Z)\n",
    "        loss = logistic_loss(A,Y)\n",
    "        dZ = A - Y\n",
    "        dw,db = grad_fn(X,dZ)\n",
    "        w = w - alpha * dw\n",
    "        b = b - alpha * db\n",
    "        \n",
    "        if epoch%100 == 0:\n",
    "            losses.append(loss)\n",
    "            if log == True:\n",
    "                print(\"After %i iterations, Loss = %f\"%(epoch,loss))\n",
    "    params ={\"w\":w,\"b\":b}\n",
    "    \n",
    "    return params,losses    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ab92e249d0a4f7111eef6667c671efc",
     "grade": true,
     "grade_id": "test_case11_train",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Contains hidden tests \n",
    "\n",
    "np.random.seed(1)\n",
    "d = 2\n",
    "m1 = 10\n",
    "X_t = np.random.randn(d,m1)\n",
    "Y_t = np.random.rand(1,m1)\n",
    "Y_t[Y_t>0.5] = 1\n",
    "Y_t[Y_t<=0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 1. 1. 0. 1. 1. 1. 0. 1.]]\n",
      "[[ 0.01624345]\n",
      " [-0.00611756]] 0\n"
     ]
    }
   ],
   "source": [
    "print(Y_t)\n",
    "w,b = initialize(d, seed=1)\n",
    "print(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dca4716c7d14c983693bcb990897820",
     "grade": false,
     "grade_id": "cell-fade22528688402f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Model Prediction (10 Points)\n",
    "\n",
    "Once we have the optimal values of model parameters $(w,b)$, we can determine the accuracy of the model on the test data.\n",
    "<center> \n",
    "    \\begin{equation*}\n",
    "     Z = w^{T}X + b\\\\\n",
    "     A=\\sigma\\left(Z\\right)  \n",
    "    \\end{equation*}\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef2c5c47a742668b6032827fe50673c4",
     "grade": false,
     "grade_id": "test_case12_predict_soln",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def model_predict(params,X,Y=np. array([]),pred_threshold=0.5):\n",
    "    '''\n",
    "    Function to calculate category predictions on given data and returns the accuracy of the predictions.\n",
    "    Inputs:\n",
    "        params: a dictionary to hold parameters w and b\n",
    "        X: training data of dimensions (d, m)\n",
    "        Y: training data labels of dimensions (1, m). If not provided, the function merely makes predictions on X\n",
    "        \n",
    "    outputs:\n",
    "        Y_Pred: Predicted class labels for X. Has dimensions (1, m)\n",
    "        acc: accuracy of prediction over X if Y is provided else, 0 \n",
    "        loss: loss of prediction over X if Y is provided else, Inf  \n",
    "    '''\n",
    "    w = params['w']\n",
    "    b = params['b']\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # Calculate Z using X, w and b\n",
    "    # Calculate A using the sigmoid - A is the set of (1,m) probabilities\n",
    "    # Calculate the prediction labels Y_Pred of size (1,m) using A and pred_threshold \n",
    "    # When A>pred_threshold Y_Pred is 1 else 0\n",
    "    # your code here\n",
    "    Z = np.dot(w.T,X) + b\n",
    "    A = sigmoid(Z)\n",
    "    Y_Pred = np.zeros((1,m))\n",
    "\n",
    "    for i in range(A.shape[1]):\n",
    "        Y_Pred[0,i] = 1 if A[0,i] > pred_threshold else 0\n",
    "    \n",
    "    \n",
    "    acc = 0\n",
    "    loss = float('inf')\n",
    "    if Y.size!=0:\n",
    "        loss = logistic_loss(A,Y)\n",
    "        acc = np.mean(Y_Pred==Y)\n",
    "    return Y_Pred, acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1066cd4d71d723dc0c48b7560385b0b5",
     "grade": true,
     "grade_id": "test_case12_predict",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Contains hidden tests \n",
    "\n",
    "np.random.seed(1)\n",
    "d = 2\n",
    "m1 = 10\n",
    "\n",
    "# Test standard\n",
    "X_t = np.random.randn(d,m1)\n",
    "Y_t = np.random.rand(1,m1)\n",
    "Y_t[Y_t>0.5] = 1\n",
    "Y_t[Y_t<=0.5] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Putting it All Together (10 Points)\n",
    "\n",
    "We will train our logistic regression model using the data we have loaded and test our predictions on diabetes classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "189ec6bd0ac8a2bd2fbb34c9ef2f5b61",
     "grade": false,
     "grade_id": "test_case13_together_soln",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#We can use a decently large learning rate becasue the features have been normalized \n",
    "#When features are not normalized, larger learning rates may cause the learning to oscillate \n",
    "#and go out of bounds leading to 'nan' errors\n",
    "#Feel free to adjust the learning rate alpha and the n_epochs to vary the test accuracy\n",
    "#You should be able to get test accuracy > 70%\n",
    "#You can go up to 75% to 80% test accuracies as well\n",
    "\n",
    "alpha = 0.2\n",
    "n_epochs = 2000\n",
    "\n",
    "# Write code to initialize parameters w and b with initialize(.) (use train_X to get feature dimensions d)\n",
    "# Use model_fit(.) to estimate the updated 'params' of the logistic regression model and calculate how the 'losses' varies \n",
    "# Use variables 'params' and 'losses' to store the outputs of model_fit(.) \n",
    "# your code here\n",
    "\n",
    "w,b = initialize(train_X.shape[0])\n",
    "params, losses = model_fit(w,b,train_X,train_Y,alpha,n_epochs,log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-76f9879f0a08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#         for epochs in np.arange(1000,3000,100):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mY_Pred_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mY_Pred_ts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_ts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_ts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-81d9dc723470>\u001b[0m in \u001b[0;36mmodel_fit\u001b[1;34m(w, b, X, Y, alpha, n_epochs, log)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# your code here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('result.csv','w', newline='') as file:\n",
    "#         with open('result.csv','w') as file:\n",
    "    fieldnames = ['alpha', 'epochs','acc_ts']\n",
    "    writer =csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    epochs = 1000\n",
    "    for alpha in np.arange(0.0001, 1, 0.0001):\n",
    "#         for epochs in np.arange(1000,3000,100):\n",
    "        w,b = initialize(train_X.shape[0])\n",
    "        params, losses = model_fit(w,b,train_X,train_Y,alpha,n_epochs,log=False)\n",
    "        Y_Pred_tr, acc_tr, loss_tr = model_predict(params,train_X,train_Y)\n",
    "        Y_Pred_ts, acc_ts, loss_ts = model_predict(params,test_X,test_Y)\n",
    "\n",
    "        writer.writerow({'alpha': alpha,'epochs': epochs, 'acc_tr':acc_tr,'acc_ts':acc_ts })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1f3f45b1c9b6c225b3df9c8b970d743",
     "grade": false,
     "grade_id": "cell-0e303eb28251a90e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Y_Pred_tr, acc_tr, loss_tr = model_predict(params,train_X,train_Y)\n",
    "Y_Pred_ts, acc_ts, loss_ts = model_predict(params,test_X,test_Y)\n",
    "print(\"Train Accuracy of the model:\",acc_tr)\n",
    "print(\"Test Accuracy of the model:\",acc_ts)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Iterations(x100)')\n",
    "plt.ylabel('Train loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7b99f61cccf2867d459f50944c31aaf",
     "grade": true,
     "grade_id": "test_case13_together",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Contains hidden tests testing accuracy of test to be greater than 0.7 with the above parameter settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ba829997ab7ee88ecb5c6c3c6e517ab",
     "grade": false,
     "grade_id": "cell-48c08bce648d4c53",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Congratulations on completing this week's assignment - building a single leayer neural network for binary classification. In the following weeks, we will learn to build and train a multilayer neural network for multi category classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
